{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 6\n",
    "\n",
    "Take a subset of the data and run the neural net presented in class:\n",
    "N can be any number greater than 1 million, but less than 10.5 million (8GB Ram recommended for all the data).\n",
    "\n",
    "data source: https://archive.ics.uci.edu/ml/machine-learning-databases/00280/\n",
    "\n",
    "Work (10 points each)\n",
    " 1. Pick 3 or more different architectures (add/subtract layers+neurons) and run the model + score. \n",
    " 1. With those same 3 architectures, run the SAME architecture but with 2 different (from sigmoid) activation functions.  Google the Keras documentation for a look at different available activations. \n",
    " 1. Take your best model from parts 1&2 and vary the batch size by at least 2 orders of magnitude\n",
    " 1. Take your best model (score) from parts 1&2 and use 3 different kernel initializers. Use a reasonable batch size.\n",
    " 1. Take your best results from #3 and try 3 different optimizers. (LMGTFY)\n",
    " 1. Take all that you’ve learned so far and give your best shot at producing a score. \n",
    "\n",
    "Questions to be  answered (These are loaded questions—be warned they are there to test your understanding):\n",
    " - 10 points - Q1: What was the effect of adding more layers/neurons.\n",
    " - 10 points - Q2: Which parameters gave you the best result and why (in your opinion) did they work.\n",
    " - 20 points Q3: For #6, how did you decide that your model was ‘done’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras import layers\n",
    "from keras.optimizers import SGD, RMSprop, Adamax, Adagrad\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import keras\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10500000. #Change this line adjust the number of rows. \n",
    "data=pd.read_csv(\"HIGGS.csv\",nrows=N,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(\"HIGGS.csv\",nrows=500000,header=None,skiprows=10500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column names from http://archive.ics.uci.edu/ml/datasets/HIGGS\n",
    "data.columns=['label','lepton pt','lepton eta','lepton phi','missing energy magnitude','missing energy phi',\n",
    "              'jet 1 pt','jet 1 eta','jet 1 phi','jet 1 b-tag','jet 2 pt','jet 2 eta','jet 2 phi','jet 2 b-tag',\n",
    "              'jet 3 pt','jet 3 eta','jet 3 phi','jet 3 b-tag','jet 4 pt','jet 4 eta','jet 4 phi','jet 4 b-tag',\n",
    "              'm_jj','m_jjj','m_lv','m_jlv','m_bb','m_wbb','m_wwbb']\n",
    "test_data.columns=['label','lepton pt','lepton eta','lepton phi','missing energy magnitude','missing energy phi',\n",
    "              'jet 1 pt','jet 1 eta','jet 1 phi','jet 1 b-tag','jet 2 pt','jet 2 eta','jet 2 phi','jet 2 b-tag',\n",
    "              'jet 3 pt','jet 3 eta','jet 3 phi','jet 3 b-tag','jet 4 pt','jet 4 eta','jet 4 phi','jet 4 b-tag',\n",
    "              'm_jj','m_jjj','m_lv','m_jlv','m_bb','m_wbb','m_wwbb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "colnames=list(data.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not ((data[\"label\"]>0)&(data[\"label\"]<1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data.iloc[:,0])\n",
    "x = np.array(data.iloc[:,1:])\n",
    "\n",
    "y_test = np.array(test_data.iloc[:,0])\n",
    "x_test = np.array(test_data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5299634285714285"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target (y) has a mean of close to .5 meaning it's well balanced between 0 and 1\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work 1\n",
    "\n",
    "Pick 3 or more different architectures (add/subtract layers+neurons) and run the model + score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 37s 4us/step - loss: 0.6554 - acc: 0.5969\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.6101 - acc: 0.6638\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 35s 3us/step - loss: 0.5910 - acc: 0.6831\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 35s 3us/step - loss: 0.5819 - acc: 0.6904\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 35s 3us/step - loss: 0.5758 - acc: 0.6952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7798235132728025"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin \n",
    "# 1 layer (prof code)\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.add(Dropout(0.10))\n",
    "model1.add(Dense(50, kernel_initializer='uniform'))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.add(Dropout(0.10))\n",
    "model1.add(Dense(1, kernel_initializer='uniform')) \n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model1.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model1.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model1.predict(x_test))\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 41s 4us/step - loss: 0.6917 - acc: 0.5294\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.6914 - acc: 0.5300\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.6475 - acc: 0.6144\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.6087 - acc: 0.6682\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.5956 - acc: 0.6825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7636162454017719"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1, kernel_initializer='uniform')) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 30s 3us/step - loss: 0.6826 - acc: 0.5485\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.6203 - acc: 0.6520\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5960 - acc: 0.6790\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5852 - acc: 0.6878\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5783 - acc: 0.6933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7771522219704127"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 2\n",
    "# Use original architecture (2 hidden layers in total) but now set all layers to have 25 neurons\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(25, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(Dropout(0.10))\n",
    "model3.add(Dense(25, kernel_initializer='uniform'))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(Dropout(0.10))\n",
    "model3.add(Dense(1, kernel_initializer='uniform')) \n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model3.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model3.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model3.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 26s 2us/step - loss: 0.6915 - acc: 0.5300\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 26s 2us/step - loss: 0.6438 - acc: 0.6216\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.6074 - acc: 0.6742\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 30s 3us/step - loss: 0.5975 - acc: 0.6808\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5934 - acc: 0.6834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7590408618992365"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 3\n",
    "# Use original architecture (2 hidden layers in total) but now set all layers to have 10 neurons\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(10, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.add(Dropout(0.10))\n",
    "model4.add(Dense(10, kernel_initializer='uniform'))\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.add(Dropout(0.10))\n",
    "model4.add(Dense(1, kernel_initializer='uniform')) \n",
    "model4.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model4.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model4.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model4.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work 2\n",
    "With those same 3 architectures, run the SAME architecture but with 2 different (from sigmoid) activation functions.  Google the Keras documentation for a look at different available activations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5655 - acc: 0.6998\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 38s 4us/step - loss: 0.5306 - acc: 0.7298\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 38s 4us/step - loss: 0.5238 - acc: 0.7346\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 38s 4us/step - loss: 0.5210 - acc: 0.7366\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 38s 4us/step - loss: 0.5191 - acc: 0.7380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8304535439981965"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1, kernel_initializer='uniform')) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.6011 - acc: 0.6721\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5710 - acc: 0.6994\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5613 - acc: 0.7069\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5559 - acc: 0.7108\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5530 - acc: 0.7129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8068294797927273"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 2\n",
    "# Use original architecture (2 hidden layers in total) but now set all layers to have 25 neurons\n",
    "# Use tanh activation\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(25, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model3.add(Activation('tanh'))\n",
    "model3.add(Dropout(0.10))\n",
    "model3.add(Dense(25, kernel_initializer='uniform'))\n",
    "model3.add(Activation('tanh'))\n",
    "model3.add(Dropout(0.10))\n",
    "model3.add(Dense(1, kernel_initializer='uniform')) \n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model3.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model3.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model3.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 26s 2us/step - loss: 0.5914 - acc: 0.6834\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 26s 2us/step - loss: 0.5760 - acc: 0.6986\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 25s 2us/step - loss: 0.5735 - acc: 0.6997\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 26s 2us/step - loss: 0.5722 - acc: 0.7003\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 26s 2us/step - loss: 0.5712 - acc: 0.7007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7884435273166096"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 3\n",
    "# Use original architecture (2 hidden layers in total) but now set all layers to have 10 neurons\n",
    "# Use relu\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(10, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(0.10))\n",
    "model4.add(Dense(10, kernel_initializer='uniform'))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(0.10))\n",
    "model4.add(Dense(1, kernel_initializer='uniform')) \n",
    "model4.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model4.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model4.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model4.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work 3\n",
    "Take your best model from parts 1&2 and vary the batch size by at least 2 orders of magnitude\n",
    "\n",
    "Note from KJ:\n",
    "\n",
    "> I tried using batch_size=10 but it took forever to run (5 minutes per epoch). The following is batch_size=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 44s 4us/step - loss: 0.6914 - acc: 0.5299\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.6913 - acc: 0.5300\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 44s 4us/step - loss: 0.6913 - acc: 0.5300\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.6912 - acc: 0.5300\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 46s 4us/step - loss: 0.6897 - acc: 0.5312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6159894554889519"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "# Batch size originally 1000, now make batch size 100000\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1, kernel_initializer='uniform')) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=100000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work 4\n",
    "\n",
    "Take your best model (score) from parts 1&2 and use 3 different kernel initializers. Use a reasonable batch size.\n",
    "\n",
    "KJ Note\n",
    "\n",
    "> results are about the same when removing the kernel_initializer from subsequent layers as shown in the first attempt here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.5587 - acc: 0.7087\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.5338 - acc: 0.7275\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 46s 4us/step - loss: 0.5280 - acc: 0.7318\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.5248 - acc: 0.7339\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5225 - acc: 0.7354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8288583828377185"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1)) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5664 - acc: 0.7020\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5369 - acc: 0.7255\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 38s 4us/step - loss: 0.5297 - acc: 0.7306\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5261 - acc: 0.7331\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5236 - acc: 0.7348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8290900525512799"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 2\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "# now use lecun_normal for initialization\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='lecun_normal')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1)) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5590 - acc: 0.7084\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5336 - acc: 0.7275\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5279 - acc: 0.7318\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5249 - acc: 0.7338\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5230 - acc: 0.7351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8277445328276265"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 3\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "# now use random_uniform for initialization\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='random_uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1)) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work 5\n",
    "\n",
    "Take your best results from #3 and try 3 different optimizers. (LMGTFY)\n",
    "\n",
    "> RMSprop, Adamax, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5714 - acc: 0.6977\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5378 - acc: 0.7245\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5292 - acc: 0.7306\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5253 - acc: 0.7333\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5232 - acc: 0.7347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8271407972356888"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "# Now use RMSprop\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1, kernel_initializer='uniform')) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "optimizer=RMSprop()\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.5673 - acc: 0.7008\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.5355 - acc: 0.7267\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.5279 - acc: 0.7320\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 45s 4us/step - loss: 0.5240 - acc: 0.7347\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.5218 - acc: 0.7360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8286814486563112"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "# Now use Adamax\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1, kernel_initializer='uniform')) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "optimizer=Adamax()\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.5818 - acc: 0.6899\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.5555 - acc: 0.7124\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 42s 4us/step - loss: 0.5468 - acc: 0.7186\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5413 - acc: 0.7226\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 41s 4us/step - loss: 0.5373 - acc: 0.7251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8148219277373501"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "# Now use Adamax\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1, kernel_initializer='uniform')) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "optimizer=Adagrad()\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work 6\n",
    "\n",
    "Take all that you’ve learned so far and give your best shot at producing a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO: Delete\n",
    "NUMBER_OF_X_TO_TAKE = 1050000\n",
    "data_subset = data.sample(NUMBER_OF_X_TO_TAKE)\n",
    "y = np.array(data_subset.iloc[:,0])\n",
    "x = np.array(data_subset.iloc[:,1:])\n",
    "\n",
    "y_test = np.array(test_data.iloc[:,0])\n",
    "x_test = np.array(test_data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050000, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1050000, 28)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1050000/1050000 [==============================] - 4s 4us/step - loss: 0.6062 - acc: 0.6673\n",
      "Epoch 2/5\n",
      "1050000/1050000 [==============================] - 3s 3us/step - loss: 0.5750 - acc: 0.6970\n",
      "Epoch 3/5\n",
      "1050000/1050000 [==============================] - 3s 3us/step - loss: 0.5642 - acc: 0.7051\n",
      "Epoch 4/5\n",
      "1050000/1050000 [==============================] - 3s 3us/step - loss: 0.5582 - acc: 0.7099\n",
      "Epoch 5/5\n",
      "1050000/1050000 [==============================] - 3s 3us/step - loss: 0.5537 - acc: 0.7127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8014222716737639"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Get a standard model\n",
    "model_best = Sequential()\n",
    "model_best.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(50))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(50))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1)) \n",
    "model_best.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_best.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model_best.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model_best.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1050000/1050000 [==============================] - 4s 4us/step - loss: 0.6071 - acc: 0.6652\n",
      "Epoch 2/5\n",
      "1050000/1050000 [==============================] - 4s 4us/step - loss: 0.5752 - acc: 0.6967\n",
      "Epoch 3/5\n",
      "1050000/1050000 [==============================] - 4s 4us/step - loss: 0.5639 - acc: 0.7061\n",
      "Epoch 4/5\n",
      "1050000/1050000 [==============================] - 4s 4us/step - loss: 0.5562 - acc: 0.7119\n",
      "Epoch 5/5\n",
      "1050000/1050000 [==============================] - 4s 4us/step - loss: 0.5498 - acc: 0.7168\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8038901782572062"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nodes: 100, 50, 20\n",
    "model_best = Sequential()\n",
    "model_best.add(Dense(100, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(50))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(20))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1)) \n",
    "model_best.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_best.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model_best.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model_best.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1050000/1050000 [==============================] - 15s 15us/step - loss: 0.6056 - acc: 0.6655\n",
      "Epoch 2/5\n",
      "1050000/1050000 [==============================] - 15s 14us/step - loss: 0.5691 - acc: 0.7028\n",
      "Epoch 3/5\n",
      "1050000/1050000 [==============================] - 15s 14us/step - loss: 0.5549 - acc: 0.7141\n",
      "Epoch 4/5\n",
      "1050000/1050000 [==============================] - 15s 14us/step - loss: 0.5450 - acc: 0.7216\n",
      "Epoch 5/5\n",
      "1050000/1050000 [==============================] - 15s 14us/step - loss: 0.5373 - acc: 0.7272\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8156218725425226"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nodes: 1000, 100, 10\n",
    "model_best = Sequential()\n",
    "model_best.add(Dense(1000, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(100))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(10))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1)) \n",
    "model_best.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_best.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model_best.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model_best.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1050000/1050000 [==============================] - 50s 48us/step - loss: 0.5969 - acc: 0.6740\n",
      "Epoch 2/5\n",
      "1050000/1050000 [==============================] - 52s 50us/step - loss: 0.5589 - acc: 0.7092\n",
      "Epoch 3/5\n",
      "1050000/1050000 [==============================] - 51s 49us/step - loss: 0.5426 - acc: 0.7213\n",
      "Epoch 4/5\n",
      "1050000/1050000 [==============================] - 50s 48us/step - loss: 0.5300 - acc: 0.7309\n",
      "Epoch 5/5\n",
      "1050000/1050000 [==============================] - 50s 48us/step - loss: 0.5202 - acc: 0.7376\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8249826782722331"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nodes: 1000, 1000, 100\n",
    "model_best = Sequential()\n",
    "model_best.add(Dense(1000, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1000))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(100))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1)) \n",
    "model_best.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_best.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model_best.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model_best.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1050000/1050000 [==============================] - 13s 12us/step - loss: 0.5993 - acc: 0.6715\n",
      "Epoch 2/5\n",
      "1050000/1050000 [==============================] - 13s 12us/step - loss: 0.5640 - acc: 0.7051\n",
      "Epoch 3/5\n",
      "1050000/1050000 [==============================] - 12s 12us/step - loss: 0.5487 - acc: 0.7168\n",
      "Epoch 4/5\n",
      "1050000/1050000 [==============================] - 12s 12us/step - loss: 0.5374 - acc: 0.7258\n",
      "Epoch 5/5\n",
      "1050000/1050000 [==============================] - 12s 12us/step - loss: 0.5294 - acc: 0.7312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8212436225815053"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nodes: 500, 200, 100\n",
    "model_best = Sequential()\n",
    "model_best.add(Dense(500, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(200))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(100))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1)) \n",
    "model_best.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_best.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model_best.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model_best.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1050000/1050000 [==============================] - 13s 12us/step - loss: 0.5981 - acc: 0.6731\n",
      "Epoch 2/5\n",
      "1050000/1050000 [==============================] - 13s 12us/step - loss: 0.5635 - acc: 0.7053\n",
      "Epoch 3/5\n",
      "1050000/1050000 [==============================] - 13s 12us/step - loss: 0.5481 - acc: 0.7175\n",
      "Epoch 4/5\n",
      "1050000/1050000 [==============================] - 12s 12us/step - loss: 0.5368 - acc: 0.7259\n",
      "Epoch 5/5\n",
      "1050000/1050000 [==============================] - 12s 12us/step - loss: 0.5287 - acc: 0.7316\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8216103285878592"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nodes: 500, 200, 100\n",
    "model_best = Sequential()\n",
    "model_best.add(Dense(500, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(200))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(100))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1)) \n",
    "model_best.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_best.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model_best.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model_best.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1050000/1050000 [==============================] - 13s 13us/step - loss: 0.6000 - acc: 0.6708\n",
      "Epoch 2/5\n",
      "1050000/1050000 [==============================] - 13s 12us/step - loss: 0.5637 - acc: 0.7052\n",
      "Epoch 3/5\n",
      "1050000/1050000 [==============================] - 12s 12us/step - loss: 0.5488 - acc: 0.7168\n",
      "Epoch 4/5\n",
      "1050000/1050000 [==============================] - 13s 12us/step - loss: 0.5382 - acc: 0.7250\n",
      "Epoch 5/5\n",
      "1050000/1050000 [==============================] - 13s 12us/step - loss: 0.5303 - acc: 0.7301\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8209309504727273"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nodes: 500, 400, 400\n",
    "model_best = Sequential()\n",
    "model_best.add(Dense(500, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(200))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(100))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1)) \n",
    "model_best.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_best.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model_best.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model_best.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1050000/1050000 [==============================] - 19s 18us/step - loss: 0.5997 - acc: 0.6715\n",
      "Epoch 2/5\n",
      "1050000/1050000 [==============================] - 19s 18us/step - loss: 0.5635 - acc: 0.7056\n",
      "Epoch 3/5\n",
      "1050000/1050000 [==============================] - 19s 18us/step - loss: 0.5479 - acc: 0.7180\n",
      "Epoch 4/5\n",
      "1050000/1050000 [==============================] - 19s 18us/step - loss: 0.5363 - acc: 0.7263\n",
      "Epoch 5/5\n",
      "1050000/1050000 [==============================] - 19s 18us/step - loss: 0.5279 - acc: 0.7324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8192945684714231"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nodes: 500, 300, 200, 100\n",
    "model_best = Sequential()\n",
    "model_best.add(Dense(500, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(300))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(200))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(100))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1)) \n",
    "model_best.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_best.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model_best.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model_best.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1050000/1050000 [==============================] - 86s 82us/step - loss: 0.5980 - acc: 0.6726\n",
      "Epoch 2/5\n",
      "1050000/1050000 [==============================] - 83s 79us/step - loss: 0.5580 - acc: 0.7093\n",
      "Epoch 3/5\n",
      "1050000/1050000 [==============================] - 82s 78us/step - loss: 0.5396 - acc: 0.7238\n",
      "Epoch 4/5\n",
      "1050000/1050000 [==============================] - 85s 81us/step - loss: 0.5267 - acc: 0.7333\n",
      "Epoch 5/5\n",
      "1050000/1050000 [==============================] - 83s 79us/step - loss: 0.5169 - acc: 0.7398\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.827730548916318"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nodes: 1000, 1000, 1000\n",
    "## This is our winning model\n",
    "model_best = Sequential()\n",
    "model_best.add(Dense(1000, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1000))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1000))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1)) \n",
    "model_best.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_best.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model_best.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model_best.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1050000/1050000 [==============================] - 49s 46us/step - loss: 0.6011 - acc: 0.6701\n",
      "Epoch 2/5\n",
      "1050000/1050000 [==============================] - 48s 45us/step - loss: 0.5632 - acc: 0.7058\n",
      "Epoch 3/5\n",
      "1050000/1050000 [==============================] - 48s 45us/step - loss: 0.5478 - acc: 0.7179\n",
      "Epoch 4/5\n",
      "1050000/1050000 [==============================] - 47s 45us/step - loss: 0.5366 - acc: 0.7261\n",
      "Epoch 5/5\n",
      "1050000/1050000 [==============================] - 48s 46us/step - loss: 0.5279 - acc: 0.7326\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8204848672154216"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nodes: 1000, 1000\n",
    "model_best = Sequential()\n",
    "model_best.add(Dense(1000, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1000))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1)) \n",
    "model_best.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_best.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model_best.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model_best.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1050000/1050000 [==============================] - 90s 85us/step - loss: 0.6077 - acc: 0.6660\n",
      "Epoch 2/5\n",
      "1050000/1050000 [==============================] - 86s 82us/step - loss: 0.5595 - acc: 0.7093\n",
      "Epoch 3/5\n",
      "1050000/1050000 [==============================] - 86s 82us/step - loss: 0.5406 - acc: 0.7239\n",
      "Epoch 4/5\n",
      "1050000/1050000 [==============================] - 86s 82us/step - loss: 0.5283 - acc: 0.7331\n",
      "Epoch 5/5\n",
      "1050000/1050000 [==============================] - 86s 82us/step - loss: 0.5194 - acc: 0.7392\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8220489030170728"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nodes: 1000, 1000, 1000\n",
    "## RMSPROP (lr=0.001)\n",
    "model_best = Sequential()\n",
    "model_best.add(Dense(1000, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1000))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1000))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1)) \n",
    "model_best.add(Activation('sigmoid'))\n",
    "\n",
    "optimizer = RMSprop(lr=0.001)\n",
    "model_best.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "\n",
    "model_best.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model_best.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use all of our data again (instead of a sample)\n",
    "y = np.array(data.iloc[:,0])\n",
    "x = np.array(data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "10500000/10500000 [==============================] - 811s 77us/step - loss: 0.5270 - acc: 0.7313\n",
      "Epoch 2/4\n",
      "10500000/10500000 [==============================] - 817s 78us/step - loss: 0.4908 - acc: 0.7568\n",
      "Epoch 3/4\n",
      "10500000/10500000 [==============================] - 815s 78us/step - loss: 0.4815 - acc: 0.7629\n",
      "Epoch 4/4\n",
      "10500000/10500000 [==============================] - 821s 78us/step - loss: 0.4760 - acc: 0.7665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8582193614693129"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## nodes: 1000, 1000, 1000\n",
    "## This is our winning model - note that it uses all of our data\n",
    "model_best = Sequential()\n",
    "model_best.add(Dense(1000, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1000))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1000))\n",
    "model_best.add(Activation('relu'))\n",
    "model_best.add(Dropout(0.10))\n",
    "model_best.add(Dense(1)) \n",
    "model_best.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model_best.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model_best.fit(x, y, epochs=4, batch_size=1000)\n",
    "roc_auc_score(y_test,model_best.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1: What was the effect of adding more layers/neurons.\n",
    "\n",
    "> It appears that adding too many layers (more than four) does not tend to help our accuracy. This of course might requiring additional tuning from our hyperparameters in conjunction with adding layers (the combinations could be endless). For us, three layers seem to be the sweet spot.\n",
    "\n",
    "> It looks like, in general, the more neurons used the higher our accuracy went. For us, 1000 neurons works really well. Unsurprisingly, training time increases greatly by the number of neurons, so I think there is a point where squeezing more juice via neurons is not worth the computational cost of thes neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q2: Which parameters gave you the best result and why (in your opinion) did they work.\n",
    "    \n",
    "> We found that the best combination is three layers with 1000 hidden nodes in each layer. Relu activation for the hidden layers seems to work best for us. The default `kernel_initializer` (uniform) and `optimizer` (SGD) worked best for us.\n",
    "\n",
    "> We suggest there are _many_ different combinations of important features for this data set. Because of this, 1000 nodes in each layer would help preserve information. One thing that was encountered is that the accuracy seemed to stall completely (at around 53%) when we decreased the learning rate (this happened very frequently when using different optimizers besides SGD). Perhaps this is due to a local minima being discovered by the optimizer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q3: For #6, how did you decide that your model was ‘done’\n",
    "\n",
    "> We chose to finally come to an end when the return on our effort was diminishing (once it took us more than 5 or so iterations to get any marginal improvement).\n",
    "\n",
    "> In actuality, I'm certain that we could spend more time working on this. For the most obvious work left, we should use more epochs and see how well our models perform over many different epochs (while looking at when they seem to be overfitting by introducing a validation dataset). Some of our architectures we are throwing away because they do not do so well at an arbitrary 5 epochs, but these slow-starters might end up performing better than our champion-algorithm after, say, 30 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
