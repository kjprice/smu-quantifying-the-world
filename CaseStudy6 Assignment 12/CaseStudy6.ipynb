{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study 6\n",
    "\n",
    "Take a subset of the data and run the neural net presented in class:\n",
    "N can be any number greater than 1 million, but less than 10.5 million (8GB Ram recommended for all the data).\n",
    "\n",
    "data source: https://archive.ics.uci.edu/ml/machine-learning-databases/00280/\n",
    "\n",
    "Work (10 points each)\n",
    " 1. Pick 3 or more different architectures (add/subtract layers+neurons) and run the model + score. \n",
    " 1. With those same 3 architectures, run the SAME architecture but with 2 different (from sigmoid) activation functions.  Google the Keras documentation for a look at different available activations. \n",
    " 1. Take your best model from parts 1&2 and vary the batch size by at least 2 orders of magnitude\n",
    " 1. Take your best model (score) from parts 1&2 and use 3 different kernel initializers. Use a reasonable batch size.\n",
    " 1. Take your best results from #3 and try 3 different optimizers. (LMGTFY)\n",
    " 1. Take all that you’ve learned so far and give your best shot at producing a score. \n",
    "\n",
    "Questions to be  answered (These are loaded questions—be warned they are there to test your understanding):\n",
    " - 10 points - Q1: What was the effect of adding more layers/neurons.\n",
    " - 10 points - Q2: Which parameters gave you the best result and why (in your opinion) did they work.\n",
    " - 20 points Q3: For #6, how did you decide that your model was ‘done’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Adamax, Adagrad\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import keras\n",
    "from pprint import pprint\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=10500000. #Change this line adjust the number of rows. \n",
    "data=pd.read_csv(\"HIGGS.csv\",nrows=N,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=pd.read_csv(\"HIGGS.csv\",nrows=500000,header=None,skiprows=10500000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#column names from http://archive.ics.uci.edu/ml/datasets/HIGGS\n",
    "data.columns=['label','lepton pt','lepton eta','lepton phi','missing energy magnitude','missing energy phi',\n",
    "              'jet 1 pt','jet 1 eta','jet 1 phi','jet 1 b-tag','jet 2 pt','jet 2 eta','jet 2 phi','jet 2 b-tag',\n",
    "              'jet 3 pt','jet 3 eta','jet 3 phi','jet 3 b-tag','jet 4 pt','jet 4 eta','jet 4 phi','jet 4 b-tag',\n",
    "              'm_jj','m_jjj','m_lv','m_jlv','m_bb','m_wbb','m_wwbb']\n",
    "test_data.columns=['label','lepton pt','lepton eta','lepton phi','missing energy magnitude','missing energy phi',\n",
    "              'jet 1 pt','jet 1 eta','jet 1 phi','jet 1 b-tag','jet 2 pt','jet 2 eta','jet 2 phi','jet 2 b-tag',\n",
    "              'jet 3 pt','jet 3 eta','jet 3 phi','jet 3 b-tag','jet 4 pt','jet 4 eta','jet 4 phi','jet 4 b-tag',\n",
    "              'm_jj','m_jjj','m_lv','m_jlv','m_bb','m_wbb','m_wwbb']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10500000 entries, 0 to 10499999\n",
      "Data columns (total 29 columns):\n",
      "label                       float64\n",
      "lepton pt                   float64\n",
      "lepton eta                  float64\n",
      "lepton phi                  float64\n",
      "missing energy magnitude    float64\n",
      "missing energy phi          float64\n",
      "jet 1 pt                    float64\n",
      "jet 1 eta                   float64\n",
      "jet 1 phi                   float64\n",
      "jet 1 b-tag                 float64\n",
      "jet 2 pt                    float64\n",
      "jet 2 eta                   float64\n",
      "jet 2 phi                   float64\n",
      "jet 2 b-tag                 float64\n",
      "jet 3 pt                    float64\n",
      "jet 3 eta                   float64\n",
      "jet 3 phi                   float64\n",
      "jet 3 b-tag                 float64\n",
      "jet 4 pt                    float64\n",
      "jet 4 eta                   float64\n",
      "jet 4 phi                   float64\n",
      "jet 4 b-tag                 float64\n",
      "m_jj                        float64\n",
      "m_jjj                       float64\n",
      "m_lv                        float64\n",
      "m_jlv                       float64\n",
      "m_bb                        float64\n",
      "m_wbb                       float64\n",
      "m_wwbb                      float64\n",
      "dtypes: float64(29)\n",
      "memory usage: 2.3 GB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 500000 entries, 0 to 499999\n",
      "Data columns (total 29 columns):\n",
      "label                       500000 non-null float64\n",
      "lepton pt                   500000 non-null float64\n",
      "lepton eta                  500000 non-null float64\n",
      "lepton phi                  500000 non-null float64\n",
      "missing energy magnitude    500000 non-null float64\n",
      "missing energy phi          500000 non-null float64\n",
      "jet 1 pt                    500000 non-null float64\n",
      "jet 1 eta                   500000 non-null float64\n",
      "jet 1 phi                   500000 non-null float64\n",
      "jet 1 b-tag                 500000 non-null float64\n",
      "jet 2 pt                    500000 non-null float64\n",
      "jet 2 eta                   500000 non-null float64\n",
      "jet 2 phi                   500000 non-null float64\n",
      "jet 2 b-tag                 500000 non-null float64\n",
      "jet 3 pt                    500000 non-null float64\n",
      "jet 3 eta                   500000 non-null float64\n",
      "jet 3 phi                   500000 non-null float64\n",
      "jet 3 b-tag                 500000 non-null float64\n",
      "jet 4 pt                    500000 non-null float64\n",
      "jet 4 eta                   500000 non-null float64\n",
      "jet 4 phi                   500000 non-null float64\n",
      "jet 4 b-tag                 500000 non-null float64\n",
      "m_jj                        500000 non-null float64\n",
      "m_jjj                       500000 non-null float64\n",
      "m_lv                        500000 non-null float64\n",
      "m_jlv                       500000 non-null float64\n",
      "m_bb                        500000 non-null float64\n",
      "m_wbb                       500000 non-null float64\n",
      "m_wwbb                      500000 non-null float64\n",
      "dtypes: float64(29)\n",
      "memory usage: 110.6 MB\n"
     ]
    }
   ],
   "source": [
    "test_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label',\n",
       " 'lepton pt',\n",
       " 'lepton eta',\n",
       " 'lepton phi',\n",
       " 'missing energy magnitude',\n",
       " 'missing energy phi',\n",
       " 'jet 1 pt',\n",
       " 'jet 1 eta',\n",
       " 'jet 1 phi',\n",
       " 'jet 1 b-tag',\n",
       " 'jet 2 pt',\n",
       " 'jet 2 eta',\n",
       " 'jet 2 phi',\n",
       " 'jet 2 b-tag',\n",
       " 'jet 3 pt',\n",
       " 'jet 3 eta',\n",
       " 'jet 3 phi',\n",
       " 'jet 3 b-tag',\n",
       " 'jet 4 pt',\n",
       " 'jet 4 eta',\n",
       " 'jet 4 phi',\n",
       " 'jet 4 b-tag',\n",
       " 'm_jj',\n",
       " 'm_jjj',\n",
       " 'm_lv',\n",
       " 'm_jlv',\n",
       " 'm_bb',\n",
       " 'm_wbb',\n",
       " 'm_wwbb']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames=list(data.columns.values)\n",
    "colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert not ((data[\"label\"]>0)&(data[\"label\"]<1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array(data.iloc[:,0])\n",
    "x = np.array(data.iloc[:,1:])\n",
    "\n",
    "y_test = np.array(test_data.iloc[:,0])\n",
    "x_test = np.array(test_data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5299634285714285"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the target (y) has a mean of close to .5 meaning it's well balanced between 0 and 1\n",
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work 1\n",
    "\n",
    "Pick 3 or more different architectures (add/subtract layers+neurons) and run the model + score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 37s 4us/step - loss: 0.6554 - acc: 0.5969\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.6101 - acc: 0.6638\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 35s 3us/step - loss: 0.5910 - acc: 0.6831\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 35s 3us/step - loss: 0.5819 - acc: 0.6904\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 35s 3us/step - loss: 0.5758 - acc: 0.6952\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7798235132728025"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Begin \n",
    "# 1 layer (prof code)\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.add(Dropout(0.10))\n",
    "model1.add(Dense(50, kernel_initializer='uniform'))\n",
    "model1.add(Activation('sigmoid'))\n",
    "model1.add(Dropout(0.10))\n",
    "model1.add(Dense(1, kernel_initializer='uniform')) \n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model1.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model1.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model1.predict(x_test))\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 41s 4us/step - loss: 0.6917 - acc: 0.5294\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.6914 - acc: 0.5300\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.6475 - acc: 0.6144\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.6087 - acc: 0.6682\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.5956 - acc: 0.6825\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7636162454017719"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('sigmoid'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1, kernel_initializer='uniform')) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 30s 3us/step - loss: 0.6826 - acc: 0.5485\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.6203 - acc: 0.6520\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5960 - acc: 0.6790\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5852 - acc: 0.6878\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5783 - acc: 0.6933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7771522219704127"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 2\n",
    "# Use original architecture (2 hidden layers in total) but now set all layers to have 25 neurons\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(25, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(Dropout(0.10))\n",
    "model3.add(Dense(25, kernel_initializer='uniform'))\n",
    "model3.add(Activation('sigmoid'))\n",
    "model3.add(Dropout(0.10))\n",
    "model3.add(Dense(1, kernel_initializer='uniform')) \n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model3.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model3.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model3.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 26s 2us/step - loss: 0.6915 - acc: 0.5300\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 26s 2us/step - loss: 0.6438 - acc: 0.6216\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.6074 - acc: 0.6742\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 30s 3us/step - loss: 0.5975 - acc: 0.6808\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5934 - acc: 0.6834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7590408618992365"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 3\n",
    "# Use original architecture (2 hidden layers in total) but now set all layers to have 10 neurons\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(10, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.add(Dropout(0.10))\n",
    "model4.add(Dense(10, kernel_initializer='uniform'))\n",
    "model4.add(Activation('sigmoid'))\n",
    "model4.add(Dropout(0.10))\n",
    "model4.add(Dense(1, kernel_initializer='uniform')) \n",
    "model4.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model4.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model4.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model4.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work 2\n",
    "With those same 3 architectures, run the SAME architecture but with 2 different (from sigmoid) activation functions.  Google the Keras documentation for a look at different available activations. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5655 - acc: 0.6998\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 38s 4us/step - loss: 0.5306 - acc: 0.7298\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 38s 4us/step - loss: 0.5238 - acc: 0.7346\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 38s 4us/step - loss: 0.5210 - acc: 0.7366\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 38s 4us/step - loss: 0.5191 - acc: 0.7380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8304535439981965"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1, kernel_initializer='uniform')) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.6011 - acc: 0.6721\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5710 - acc: 0.6994\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5613 - acc: 0.7069\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5559 - acc: 0.7108\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 29s 3us/step - loss: 0.5530 - acc: 0.7129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8068294797927273"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 2\n",
    "# Use original architecture (2 hidden layers in total) but now set all layers to have 25 neurons\n",
    "# Use tanh activation\n",
    "model3 = Sequential()\n",
    "model3.add(Dense(25, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model3.add(Activation('tanh'))\n",
    "model3.add(Dropout(0.10))\n",
    "model3.add(Dense(25, kernel_initializer='uniform'))\n",
    "model3.add(Activation('tanh'))\n",
    "model3.add(Dropout(0.10))\n",
    "model3.add(Dense(1, kernel_initializer='uniform')) \n",
    "model3.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model3.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model3.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model3.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 26s 2us/step - loss: 0.5914 - acc: 0.6834\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 26s 2us/step - loss: 0.5760 - acc: 0.6986\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 25s 2us/step - loss: 0.5735 - acc: 0.6997\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 26s 2us/step - loss: 0.5722 - acc: 0.7003\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 26s 2us/step - loss: 0.5712 - acc: 0.7007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7884435273166096"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 3\n",
    "# Use original architecture (2 hidden layers in total) but now set all layers to have 10 neurons\n",
    "# Use relu\n",
    "model4 = Sequential()\n",
    "model4.add(Dense(10, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(0.10))\n",
    "model4.add(Dense(10, kernel_initializer='uniform'))\n",
    "model4.add(Activation('relu'))\n",
    "model4.add(Dropout(0.10))\n",
    "model4.add(Dense(1, kernel_initializer='uniform')) \n",
    "model4.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model4.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model4.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model4.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work 3\n",
    "Take your best model from parts 1&2 and vary the batch size by at least 2 orders of magnitude\n",
    "\n",
    "Note from KJ:\n",
    "\n",
    "> I tried using batch_size=10 but it took forever to run (5 minutes per epoch). The following is batch_size=10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 44s 4us/step - loss: 0.6914 - acc: 0.5299\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.6913 - acc: 0.5300\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 44s 4us/step - loss: 0.6913 - acc: 0.5300\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.6912 - acc: 0.5300\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 46s 4us/step - loss: 0.6897 - acc: 0.5312\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6159894554889519"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "# Batch size originally 1000, now make batch size 100000\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1, kernel_initializer='uniform')) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=100000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work 4\n",
    "\n",
    "Take your best model (score) from parts 1&2 and use 3 different kernel initializers. Use a reasonable batch size.\n",
    "\n",
    "KJ Note\n",
    "\n",
    "> results are about the same when removing the kernel_initializer from subsequent layers as shown in the first attempt here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.5587 - acc: 0.7087\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.5338 - acc: 0.7275\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 46s 4us/step - loss: 0.5280 - acc: 0.7318\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.5248 - acc: 0.7339\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5225 - acc: 0.7354\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8288583828377185"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1)) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5664 - acc: 0.7020\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5369 - acc: 0.7255\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 38s 4us/step - loss: 0.5297 - acc: 0.7306\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5261 - acc: 0.7331\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5236 - acc: 0.7348\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8290900525512799"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 2\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "# now use lecun_normal for initialization\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='lecun_normal')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1)) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5590 - acc: 0.7084\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5336 - acc: 0.7275\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5279 - acc: 0.7318\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5249 - acc: 0.7338\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5230 - acc: 0.7351\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8277445328276265"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 3\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "# now use random_uniform for initialization\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='random_uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1)) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work 5\n",
    "\n",
    "Take your best results from #3 and try 3 different optimizers. (LMGTFY)\n",
    "\n",
    "> RMSprop, Adamax, Adagrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5714 - acc: 0.6977\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5378 - acc: 0.7245\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5292 - acc: 0.7306\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5253 - acc: 0.7333\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5232 - acc: 0.7347\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8271407972356888"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "# Now use RMSprop\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1, kernel_initializer='uniform')) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "optimizer=RMSprop()\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.5673 - acc: 0.7008\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.5355 - acc: 0.7267\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 40s 4us/step - loss: 0.5279 - acc: 0.7320\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 45s 4us/step - loss: 0.5240 - acc: 0.7347\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.5218 - acc: 0.7360\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8286814486563112"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "# Now use Adamax\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1, kernel_initializer='uniform')) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "optimizer=Adamax()\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.5818 - acc: 0.6899\n",
      "Epoch 2/5\n",
      "10500000/10500000 [==============================] - 43s 4us/step - loss: 0.5555 - acc: 0.7124\n",
      "Epoch 3/5\n",
      "10500000/10500000 [==============================] - 42s 4us/step - loss: 0.5468 - acc: 0.7186\n",
      "Epoch 4/5\n",
      "10500000/10500000 [==============================] - 39s 4us/step - loss: 0.5413 - acc: 0.7226\n",
      "Epoch 5/5\n",
      "10500000/10500000 [==============================] - 41s 4us/step - loss: 0.5373 - acc: 0.7251\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8148219277373501"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Begin Attempt 1\n",
    "# Add a layer (3 hidden layers in total) with 50 neurons\n",
    "# Now use a relu\n",
    "# Now use Adamax\n",
    "model2 = Sequential()\n",
    "model2.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(50, kernel_initializer='uniform'))\n",
    "model2.add(Activation('relu'))\n",
    "model2.add(Dropout(0.10))\n",
    "model2.add(Dense(1, kernel_initializer='uniform')) \n",
    "model2.add(Activation('sigmoid'))\n",
    "\n",
    "optimizer=Adagrad()\n",
    "model2.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=optimizer)\n",
    "\n",
    "model2.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model2.predict(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work 6\n",
    "\n",
    "Take all that you’ve learned so far and give your best shot at producing a score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Begin \n",
    "# 1 layer (prof code)\n",
    "model1 = Sequential()\n",
    "model1.add(Dense(50, input_dim=x.shape[1], kernel_initializer='uniform')) # X_train.shape[1] == 28 here\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.10))\n",
    "model1.add(Dense(50, kernel_initializer='uniform'))\n",
    "model1.add(Activation('relu'))\n",
    "model1.add(Dropout(0.10))\n",
    "model1.add(Dense(1, kernel_initializer='uniform')) \n",
    "model1.add(Activation('sigmoid'))\n",
    "\n",
    "sgd = SGD(lr=0.1, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model1.compile(loss='binary_crossentropy', metrics=['accuracy'], optimizer=sgd)\n",
    "\n",
    "model1.fit(x, y, epochs=5, batch_size=1000)\n",
    "roc_auc_score(y_test,model1.predict(x_test))\n",
    "#end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
